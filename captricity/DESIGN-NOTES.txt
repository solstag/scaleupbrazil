Design notes for Captricity-related tools


scan survey forms
-----------------

- scanning happens at FIOCRUZ
- each day, the interviews that have been scanned are uploaded via web interface; they then show up
  in a folder on lazersfeld, with one folder for each day. each scanned file's name identifies the
  state and questionnaire id of the survey it contains


upload
------

- go through the folders containing scanned files and figure out which ones have not yet been uploaded
- prep the scanned forms by rotating, converting into new formats, etc as appropriate
- for each interview to be uploaded, figure out which document/template it should be associated with
- create a job for each document/template we're going to use, upload the appropriate surveys, and start the job


download
--------

- figure out which jobs have finished and have not yet been downloaded
- download all of the new interviews in .csv format (how should we organize downloaded interviews?)

conflict detection
------------------
- for all of the surveys downloaded so far, figure out what discrepancies there are between the
  vargas and captricity datasets
- assemble those discrepancies in a file that can be used by the adjudication app
- Q: how to handle --Impossible--, etc?

adjudication
------------
- humans open up the adjudication app in a web browser
- perhaps there is some overview (maybe not)
- for each conflict that needs to be resolved, show the image from the scan, and a text field
- once the adjudicated response has been obtained, store it in a resolution datafile. if it doesn't agree with either the vargas or the captricity answer, mark for further review

updating final dataset
----------------------
- start with the vargas dataset as the final dataset
- double-check that the resolution datafile has no duplicate resolutions
- for each entry in the resolution datafile, update the final dataset

IDs
---
Each individual questionnaire can be uniquely identified by the combination of the two-digit state code and the five-digit questionnaire number. The questionnaire ID will be the state code and the questionnaire number separated by an underscore. For example, for questionnaire number 123 from the state with state code 11, the id would be 11_00123.

config directory
----------------
At various points the scripts will look for the following things in the configuration directory, ~/.scaleupbrazil/

* captricity-token : a file with the captricity API token
* scanned-forms/ : a symlink to a directory with the location of the folders containing scanned pdf files
* lastdownload : file with the timestamp of the last set of downloads from the captricity server
* downloaded-data/ : a symlink to a directory with the location of the direcotry to use for downloaded data resulting
  from captricity jobs
* template-ids.json : a symlink to a file with entries mapping diffent paths through the survey to the corresponding template/document ids
* survey-paths.csv : a symlink to a .csv file which has the questionnaire ids and information about which skip patterns to use. we need this to pick the appropriate templates for each form
* captricity-vargas-diffs.csv : a symlink to a .csv file which has the questionnaire ids and variable names of items where
  captricity and vargas produced different answers. this file should be cumulative (ie, it should have all questions where
  there was ever a diff, rather than all questions with unresolved diffs)
* rawscandirs : a file that has the directories where we should look for raw uploaded scans (one directory per line)
* collectedrawpdfs : a symlink to the directory where raw scans should be copied

data directories
----------------
* the tool for uploading scans will put the pdfs / tiffs into a directory RAWSCANS; the grab-daily-scans.py tool will read through those scans and put them into a directory based on the day's date

* on the server, there will be a directory structure like

brazil/
  raw-scans/
     * any unprocessed .pdfs will go in here
  converted-pdfs/
     20100731/
     20100801/
        -> copies of pdfs that were converted to jpgs on 20100801 will
           go here
  converted-jpgs/
     20100731/
     20100801/
        -> jpg images of each page of the questionnaires converted  
           from pdf on 2010 08 01 will go here; this is where
           scripts that upload files to start the job will look
  downloaded-data/
      20100731/
      20100801/
        -> csv files with the data downloaded from jobs that finished on this date
           (TODO? - or, should it be jobs that were started on this date, so that they
            are the same as the upload directories?)





